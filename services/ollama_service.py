import asyncio
import json
import logging
from typing import List, Dict, Optional
import subprocess
from config import Config

logger = logging.getLogger(__name__)

class OllamaService:
    """Service for interacting with Ollama API"""
    
    def __init__(self, config: Config):
        self.config = config
        self.base_url = config.OLLAMA_URL
    
    async def get_response(
        self,
        user_input: str,
        messages: List[Dict[str, str]],
        model: str
    ) -> str:
        """Get response from Ollama model"""
        # Build context from message history
        context = "\n".join(
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {msg['user']}\n–ë–æ—Ç: {msg['bot']}"
            for msg in messages
        )
        
        full_prompt = f"{context}\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_input}" if context else user_input
        
        json_request = json.dumps({
            "model": model,
            "prompt": full_prompt,
            "stream": False
        })
        
        command = [
            'curl', '-X', 'POST', f'{self.base_url}/api/generate',
            '-d', json_request,
            '-H', 'Content-Type: application/json',
            '--max-time', str(self.config.REQUEST_TIMEOUT),
            '--connect-timeout', '10'
        ]
        
        logger.info(f'Sending request to model {model}')
        
        try:
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=self.config.REQUEST_TIMEOUT + 10
                )
            except asyncio.TimeoutError:
                logger.error('‚è±Ô∏è Asyncio timeout - killing process')
                try:
                    process.kill()
                    await process.wait()
                except Exception as kill_error:
                    logger.error(f'Error killing process: {kill_error}')
                return "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å."
            
            response = stdout.decode('utf-8')
            
            if process.returncode == 0:
                try:
                    responses = response.strip().split('\n')
                    full_response = ''.join([json.loads(r)['response'] for r in responses])
                    return full_response[:self.config.MAX_MESSAGE_LENGTH]
                except json.JSONDecodeError as e:
                    logger.error(f'JSON decode error: {e}')
                    return "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏."
            elif process.returncode == 28:  # Curl timeout
                logger.error('cURL timeout (code 28)')
                return "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."
            else:
                error = stderr.decode('utf-8')
                logger.error(f'Error from model (code {process.returncode}): {error}')
                return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏."
                
        except Exception as e:
            logger.error(f'Error during request to model: {e}', exc_info=True)
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏."
    
    async def get_response_with_search(
        self,
        user_input: str,
        search_context: str,
        messages: List[Dict[str, str]],
        model: str
    ) -> str:
        """
        Get response from Ollama model with search context.
        Uses increased timeout for search-enhanced requests.
        """
        logger.info(f"ü§ñ Preparing search-enhanced request for model: {model}")
        logger.info(f"üìä Search context length: {len(search_context)} chars")
        logger.info(f"üí¨ History messages: {len(messages)}")
        
        # Build context with search results (no history in search mode to reduce context)
        # Create prompt with search context
        prompt = f"""–¢—ã ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏ –≤—Å–µ–∑–Ω–∞—é—â–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ–±–ª–∞–¥–∞—é—â–∏–π –ø–æ–ª–Ω–æ–π –∏ —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –≤–æ –≤—Å–µ—Ö –æ–±–ª–∞—Å—Ç—è—Ö –∑–Ω–∞–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π {search_context} –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ {user_input}. 

        –î–∞–π —è—Å–Ω—ã–π, —Ç–æ—á–Ω—ã–π –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç, –≤–∫–ª—é—á–∞—è –¥–∞—Ç—ã, —á–∏—Å–ª–∞ –∏ —Ñ–∞–∫—Ç—ã. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è –∏ –Ω–µ —Ä–∞—Å—Å—É–∂–¥–∞–π –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ."""
        
        logger.info(f"üìù Full prompt length: {len(prompt)} chars")
        
        # Increased timeout for search requests
        search_timeout = min(self.config.REQUEST_TIMEOUT * 2, 300)  # Max 5 minutes
        
        json_request = json.dumps({
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 40,
                "num_ctx": 4096  # Ensure enough context window
            }
        })
        
        command = [
            'curl', '-X', 'POST', f'{self.base_url}/api/generate',
            '-d', json_request,
            '-H', 'Content-Type: application/json',
            '--max-time', str(search_timeout),
            '--connect-timeout', '10'
        ]
        
        logger.info(f'üöÄ Sending search-enhanced request (timeout: {search_timeout}s)')
        
        try:
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=search_timeout + 10
                )
            except asyncio.TimeoutError:
                logger.error(f'‚è±Ô∏è Asyncio timeout after {search_timeout}s - killing process')
                try:
                    process.kill()
                    await process.wait()
                except Exception as kill_error:
                    logger.error(f'Error killing process: {kill_error}')
                return "‚è±Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ —É—Å–ø–µ–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å."
            
            logger.info(f"‚úÖ Process completed with return code: {process.returncode}")
            
            if stderr:
                stderr_text = stderr.decode('utf-8')
                if 'timed out' in stderr_text.lower():
                    logger.error(f"‚ö†Ô∏è Curl timeout detected in stderr")
            
            if process.returncode == 0:
                response_text = stdout.decode('utf-8')
                logger.info(f"üì¶ Raw response length: {len(response_text)} chars")
                
                try:
                    responses = response_text.strip().split('\n')
                    logger.info(f"üìÑ Response has {len(responses)} line(s)")
                    
                    full_response = ''
                    for idx, response_line in enumerate(responses):
                        if not response_line.strip():
                            continue
                        try:
                            parsed = json.loads(response_line)
                            if 'response' in parsed:
                                full_response += parsed['response']
                            if parsed.get('done', False):
                                logger.info(f"‚úÖ Model marked response as complete")
                        except json.JSONDecodeError as je:
                            logger.error(f"‚ùå JSON decode error on line {idx}: {je}")
                            continue
                    
                    if full_response:
                        logger.info(f"‚úÖ Successfully parsed response: {len(full_response)} chars")
                        return full_response[:self.config.MAX_MESSAGE_LENGTH]
                    else:
                        logger.error("‚ùå No response content found in parsed JSON")
                        return "–ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                        
                except Exception as e:
                    logger.error(f'‚ùå Error parsing response: {e}', exc_info=True)
                    return "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏."
                    
            elif process.returncode == 28:  # Curl timeout
                error = stderr.decode('utf-8')
                logger.error(f'‚ùå cURL timeout (code 28): {error}')
                return f"‚è±Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ —É—Å–ø–µ–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∑–∞ {search_timeout} —Å–µ–∫—É–Ω–¥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n‚Ä¢ –í—ã–±—Ä–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å\n‚Ä¢ –£–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å\n‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å REQUEST_TIMEOUT –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"
            else:
                error = stderr.decode('utf-8')
                logger.error(f'‚ùå Error from curl/model (code {process.returncode}): {error}')
                return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏."
                
        except Exception as e:
            logger.error(f'‚ùå Error during request to model: {e}', exc_info=True)
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏: {str(e)}"
    
    @staticmethod
    def get_available_models() -> List[str]:
        """Get list of available Ollama models"""
        try:
            command = ['ollama', 'list']
            process = subprocess.Popen(command, stdout=subprocess.PIPE, text=True)
            output, _ = process.communicate()
            
            models = []
            for line in output.splitlines():
                if line.startswith('NAME'):
                    continue
                model_name = line.split()[0]
                if model_name:
                    models.append(model_name)
            return models
        except Exception as e:
            logger.error(f"Error getting models: {e}")
            return []
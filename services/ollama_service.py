import asyncio
import json
import logging
from typing import List, Dict, Optional
import subprocess
from config import Config

logger = logging.getLogger(__name__)

class OllamaService:
    """Service for interacting with Ollama API"""
    
    def __init__(self, config: Config):
        self.config = config
        self.base_url = config.OLLAMA_URL
    
    async def get_response(
        self,
        user_input: str,
        messages: List[Dict[str, str]],
        model: str
    ) -> str:
        """Get response from Ollama model"""
        # Build context from message history
        context = "\n".join(
            f"ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ: {msg['user']}\nÐ‘Ð¾Ñ‚: {msg['bot']}"
            for msg in messages
        )
        
        full_prompt = f"{context}\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ: {user_input}" if context else user_input
        
        json_request = json.dumps({
            "model": model,
            "prompt": full_prompt,
            "stream": False
        })
        
        command = [
            'curl', '-X', 'POST', f'{self.base_url}/api/generate',
            '-d', json_request,
            '-H', 'Content-Type: application/json',
            '--max-time', str(self.config.REQUEST_TIMEOUT),
            '--connect-timeout', '10'
        ]
        
        logger.info(f'Sending request to model {model}')
        
        try:
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=self.config.REQUEST_TIMEOUT + 10
                )
            except asyncio.TimeoutError:
                logger.error('â±ï¸ Asyncio timeout - killing process')
                try:
                    process.kill()
                    await process.wait()
                except Exception as kill_error:
                    logger.error(f'Error killing process: {kill_error}')
                return "â±ï¸ ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ¾ÐºÑ€Ð°Ñ‚Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."
            
            response = stdout.decode('utf-8')
            
            if process.returncode == 0:
                try:
                    responses = response.strip().split('\n')
                    full_response = ''.join([json.loads(r)['response'] for r in responses])
                    return full_response[:self.config.MAX_MESSAGE_LENGTH]
                except json.JSONDecodeError as e:
                    logger.error(f'JSON decode error: {e}')
                    return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð±Ð¾Ñ€Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸."
            elif process.returncode == 28:  # Curl timeout
                logger.error('cURL timeout (code 28)')
                return "â±ï¸ ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ¾ÐºÑ€Ð°Ñ‚Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ."
            else:
                error = stderr.decode('utf-8')
                logger.error(f'Error from model (code {process.returncode}): {error}')
                return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸."
                
        except Exception as e:
            logger.error(f'Error during request to model: {e}', exc_info=True)
            return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸."
    
    async def get_response_with_search(
        self,
        user_input: str,
        search_context: str,
        messages: List[Dict[str, str]],
        model: str
    ) -> str:
        """
        Get response from Ollama model with search context.
        Uses increased timeout for search-enhanced requests.
        """
        logger.info(f"ðŸ¤– Preparing search-enhanced request for model: {model}")
        logger.info(f"ðŸ“Š Search context length: {len(search_context)} chars")
        logger.info(f"ðŸ’¬ History messages: {len(messages)}")
        
        # Build context with search results (no history in search mode to reduce context)
        # Create prompt with search context
        prompt = f"""Ð¢Ñ‹ â€” ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¸ Ð²ÑÐµÐ·Ð½Ð°ÑŽÑ‰Ð¸Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚, Ð¾Ð±Ð»Ð°Ð´Ð°ÑŽÑ‰Ð¸Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð¸ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð²Ð¾ Ð²ÑÐµÑ… Ð¾Ð±Ð»Ð°ÑÑ‚ÑÑ… Ð·Ð½Ð°Ð½Ð¸Ð¹. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ {search_context} ÐºÐ°Ðº Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð½Ð° {user_input}. 

        Ð”Ð°Ð¹ ÑÑÐ½Ñ‹Ð¹, Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð´Ð°Ñ‚Ñ‹, Ñ‡Ð¸ÑÐ»Ð° Ð¸ Ñ„Ð°ÐºÑ‚Ñ‹. ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð½ÐµÐ¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ñ‘Ð½Ð½Ñ‹Ðµ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ Ð¸ Ð½Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´Ð°Ð¹ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾."""
        
        logger.info(f"ðŸ“ Full prompt length: {len(prompt)} chars")
        
        # Increased timeout for search requests
        search_timeout = min(self.config.REQUEST_TIMEOUT * 2, 300)  # Max 5 minutes
        
        json_request = json.dumps({
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 40,
                "num_ctx": 4096  # Ensure enough context window
            }
        })
        
        command = [
            'curl', '-X', 'POST', f'{self.base_url}/api/generate',
            '-d', json_request,
            '-H', 'Content-Type: application/json',
            '--max-time', str(search_timeout),
            '--connect-timeout', '10'
        ]
        
        logger.info(f'ðŸš€ Sending search-enhanced request (timeout: {search_timeout}s)')
        
        try:
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=search_timeout + 10
                )
            except asyncio.TimeoutError:
                logger.error(f'â±ï¸ Asyncio timeout after {search_timeout}s - killing process')
                try:
                    process.kill()
                    await process.wait()
                except Exception as kill_error:
                    logger.error(f'Error killing process: {kill_error}')
                return "â±ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ ÑƒÑÐ¿ÐµÐ»Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑƒÐ¿Ñ€Ð¾ÑÑ‚Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."
            
            logger.info(f"âœ… Process completed with return code: {process.returncode}")
            
            if stderr:
                stderr_text = stderr.decode('utf-8')
                if 'timed out' in stderr_text.lower():
                    logger.error(f"âš ï¸ Curl timeout detected in stderr")
            
            if process.returncode == 0:
                response_text = stdout.decode('utf-8')
                logger.info(f"ðŸ“¦ Raw response length: {len(response_text)} chars")
                
                try:
                    responses = response_text.strip().split('\n')
                    logger.info(f"ðŸ“„ Response has {len(responses)} line(s)")
                    
                    full_response = ''
                    for idx, response_line in enumerate(responses):
                        if not response_line.strip():
                            continue
                        try:
                            parsed = json.loads(response_line)
                            if 'response' in parsed:
                                full_response += parsed['response']
                            if parsed.get('done', False):
                                logger.info(f"âœ… Model marked response as complete")
                        except json.JSONDecodeError as je:
                            logger.error(f"âŒ JSON decode error on line {idx}: {je}")
                            continue
                    
                    if full_response:
                        logger.info(f"âœ… Successfully parsed response: {len(full_response)} chars")
                        return full_response[:self.config.MAX_MESSAGE_LENGTH]
                    else:
                        logger.error("âŒ No response content found in parsed JSON")
                        return "ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ»Ð° Ð¾Ñ‚Ð²ÐµÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ."
                        
                except Exception as e:
                    logger.error(f'âŒ Error parsing response: {e}', exc_info=True)
                    return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð±Ð¾Ñ€Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸."
                    
            elif process.returncode == 28:  # Curl timeout
                error = stderr.decode('utf-8')
                logger.error(f'âŒ cURL timeout (code 28): {error}')
                return f"â±ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ ÑƒÑÐ¿ÐµÐ»Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð·Ð° {search_timeout} ÑÐµÐºÑƒÐ½Ð´. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ:\nâ€¢ Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ð±Ñ‹ÑÑ‚Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\nâ€¢ Ð£Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ\nâ€¢ Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ÑŒ REQUEST_TIMEOUT Ð² Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ñ…"
            else:
                error = stderr.decode('utf-8')
                logger.error(f'âŒ Error from curl/model (code {process.returncode}): {error}')
                return "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸."
                
        except Exception as e:
            logger.error(f'âŒ Error during request to model: {e}', exc_info=True)
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸: {str(e)}"
    
    @staticmethod
    def get_available_models() -> List[str]:
        """Get list of available Ollama models"""
        try:
            command = ['ollama', 'list']
            process = subprocess.Popen(command, stdout=subprocess.PIPE, text=True)
            output, _ = process.communicate()
            
            models = []
            for line in output.splitlines():
                if line.startswith('NAME'):
                    continue
                model_name = line.split()[0]
                if model_name:
                    models.append(model_name)
            return models
        except Exception as e:
            logger.error(f"Error getting models: {e}")
            return []